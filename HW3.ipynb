{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tJBXiruTsjm7",
        "outputId": "e59417fe-e9be-4b69-a9c0-fd55f05bb946"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.7-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.7 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZJZaMDNblLJU"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keyfile = open(\"key.txt\", \"r\", encoding='latin-1')\n",
        "key = keyfile.readline()\n",
        "openai.api_key = key"
      ],
      "metadata": {
        "id": "tf5EMYzHvy_g"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('抖音.txt', 'r', encoding='latin-1') as fh:\n",
        "    tmp = fh.read()\n",
        "    itemlist1 = tmp.split(',')"
      ],
      "metadata": {
        "id": "10x23SU9okHW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('Porn.txt', 'r', encoding='latin-1') as fh:\n",
        "    tmp = fh.read()\n",
        "    itemlist2 = tmp.split(',')"
      ],
      "metadata": {
        "id": "-ukP8IouuOk4"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('meta.txt', 'r', encoding='latin-1') as fh:\n",
        "    tmp = fh.read()\n",
        "    itemlist3 = tmp.split(',')"
      ],
      "metadata": {
        "id": "nQ61DK_avdnU"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "itemlist1 = str(itemlist1)"
      ],
      "metadata": {
        "id": "qC27FY5MvxlJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [itemlist1[0:3200], itemlist1[3201:6400], \n",
        "        itemlist1[6401:9600], itemlist1[9601:12800], itemlist1[12801:16000], itemlist1[16001:19200], itemlist1[19201:22400]]"
      ],
      "metadata": {
        "id": "Roy9uwyTwF2u"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "D9YB6FuQw-sr",
        "outputId": "5a46c52c-9494-492b-ddad-c3519cf92040"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'caption\\', \"\\\\nHamid helps families go on TikTok live. Watch how the BBC investigated TikTok\\'s commission from digital gifts Agencies like these\", \\' known as \"livestreaming guilds\" and based all around the world\\', \\' are contracted by TikTok to help content creators produce more appealing livestreams.\\\\nTikTok pays them a commission according to the duration of livestreams and the value of gifts received\\', \\' the agencies told the BBC. The emphasis on duration means TikTokers\\', \\' including children in the Syrian camps\\', \\' go live for hours at a time. Marwa Fatafta\\', \\' from digital rights organisation Access Now\\', \\' says these livestreams run contrary to TikTok\\\\\\'s own policies to \"prevent the harm\\', \\' endangerment or exploitation\" of minors on the platform.\\\\n\\\\n\\']'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatgptfn(sub_list):\n",
        "    result = ''\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an assistant\"},\n",
        "            {\"role\": \"user\", \"content\": f\"{sub_list} :give me a summary\"}\n",
        "        ]\n",
        "    )\n",
        "    for choice in response.choices:\n",
        "        result += choice.message.content\n",
        "    return result"
      ],
      "metadata": {
        "id": "VR8uvPtfxFHB"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "for i in range(0,5):\n",
        "    data[i] = chatgptfn(data[i])\n",
        "    time.sleep(20) "
      ],
      "metadata": {
        "id": "PyHfeARIxSgZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = ''\n",
        "for i in range(0,5):\n",
        "    data1 = data1 + data[i]"
      ],
      "metadata": {
        "id": "4WnC9Pll1BGe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "v55xzpup1I27",
        "outputId": "e0636c20-588e-4ebd-ea61-f79253ceb97c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Syrian families living in refugee camps are using TikTok to raise money through livestreams, using British SIM cards since it is believed British viewers are the most generous. Viewers send virtual gifts costing real money, which can be withdrawn as cash, but the BBC has found that TikTok takes a 69% cut from the value of the gifts. Middlemen in the refugee camps sell their livestock to access the internet and use TikTok to work with families in order to pay them most of the profits, minus their running costs. However, families said they only receive a tiny fraction of the sums donated to them.The BBC investigated TikTok\\'s commission from digital gifts and found that the company contracts with agencies known as \"livestreaming guilds\" around the world to help content creators produce more appealing livestreams. These agencies are paid a commission by TikTok based on the duration of livestreams and the value of gifts received. However, this emphasis on duration means users, including children in Syrian camps, are going live for hours, which goes against TikTok\\'s own policies to prevent harm, endangerment, or exploitation of minors on the platform.I\\'m sorry, can you please provide more context on what you need a summary of?Sure! Can you please clarify what you would like a summary of?Sure! Can you please give me more information about what you would like a summary of?'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "itemlist2 = str(itemlist2)"
      ],
      "metadata": {
        "id": "kxhf3pAM733u"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [itemlist2[0:3200], itemlist2[3201:6400], \n",
        "        itemlist2[6401:9600], itemlist2[9601:12800], itemlist2[12801:16000], itemlist2[16001:19200], itemlist2[19201:22400]]"
      ],
      "metadata": {
        "id": "0Zf4A9gc8Id5"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "HFd7U7tP8R_X",
        "outputId": "95c91e79-6af8-448f-dc03-31589761c571"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\" she says\\', \\' holding back tears. \"How would they feel if they saw this content?\"\\\\nThe threat intensified when both Kate\\\\\\'s home and work addresses were published below the video - a practice known as doxing.\\\\n\"I became completely paranoid - \\\\\\'Who knows my address? Is it someone I know that\\\\\\'s done this?\\\\\\'\\\\n\"I was thinking\\', \" \\'I\\'m really in trouble here\", \" this isn\\'t just some people on the internet mouthing off\", \\' there\\\\\\'s actually a real danger.\\\\\\'\"\\\\nFrom her experience supporting others in similar situations\\', \\' Kate knew exactly what to do if someone becomes a victim - but in that moment she froze.\\\\n\"I didn\\\\\\'t follow any of my own advice\\', \\'\" she says. \"Kate the campaigner was very strong and didn\\\\\\'t show any vulnerability - and then there was me\\', \\' Kate\\', \\' who was really scared.\"\\\\nA colleague reported the video\\', \\' vicious comments and doxing to Twitter\\', \\' and they were all taken down from the platform. But once any deepfake has been published and shared online it\\\\\\'s difficult to remove it from circulation entirely.\\\\n\"I just wanted that video off the internet\\', \\'\" Kate says\\', \\' \"but there was nothing I could do about it.\"\\\\nThere\\\\\\'s a marketplace for deepfakes in online forums. People post requests for videos to be made of their wives\\', \\' neighbours and co-workers and - unfathomable as it might seem - even their mothers\\', \" daughters and cousins.\\\\nContent creators respond with step-by-step instructions - what source material they\\'ll need\", \\' advice on which filming angles work best\\', \\' and price tags for the work.\\\\nA deepfake content creator based in south-east England\\', \\' Gorkem\\', \\' spoke to the BBC anonymously. He began creating celebrity deepfakes for his own gratification - he says they allow people to \"realise their fantasies in ways that really wasn\\\\\\'t [sic] possible before\".\\\\nLater\\', \\' Gorkem moved on to deepfaking women he was attracted to\\', \\' including colleagues at his day job who he barely knew.\\\\n\\\\n\\']'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def chatgptfn(sub_list):\n",
        "    result = ''\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an assistant\"},\n",
        "            {\"role\": \"user\", \"content\": f\"{sub_list} :give me a summary\"}\n",
        "        ]\n",
        "    )\n",
        "    for choice in response.choices:\n",
        "        result += choice.message.content\n",
        "    return result"
      ],
      "metadata": {
        "id": "yYoUh7Po8eVi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,7):\n",
        "    data[i] = chatgptfn(data[i])\n",
        "    time.sleep(20) "
      ],
      "metadata": {
        "id": "6yNSjhQp8jgh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2 = ''\n",
        "for i in range(0,7):\n",
        "    data2 = data2 + data[i]"
      ],
      "metadata": {
        "id": "DQl_p42b9Z6-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "L8Gejg_n9kwY",
        "outputId": "e6ae26b7-67ab-411b-861a-bfa4ddfe37c7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The article is about deepfake pornography, which is a form of image-based sexual abuse. Deepfakes are artificial intelligence-generated videos that manipulate someone's face onto another person's body, often for pornographic use. The article discusses the case of Kate Isaacs, who discovered a deepfake video of herself on Twitter, causing her great distress. The article also highlights the fact that deepfakes are increasingly being used for non-consensual pornography and that a loophole in UK law means that video creators often do not face legal consequences. The article calls for the implementation of the long-awaited UK-wide Online Safety Bill and discusses the activism of Kate Isaacs, who founded the #NotYourPorn campaign.The article discusses the increasing threat of deepfakes, particularly for women who may become the non-consenting subjects of the manipulated content. It tells the story of Kate, a victim of a doxed deepfake, and her fear and frustration surrounding the situation. The article also delves into the market for deepfake creation, including requests for deeply personal creations, and the anonymous content creators who fulfill these requests.I'm sorry, I need more information. A summary of what topic or subject?Sure! However, I need more information about what you'd like me to summarize. Could you please provide some context or topic?I'm sorry, please clarify what you would like me to summarize.I'm sorry, I'm not sure what you would like me to summarize. Could you please be more specific about what you need assistance with?Sure, I can give you a summary. However, I'll need you to clarify what specifically you would like me to summarize. Could you provide me with more information?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "itemlist3 = str(itemlist3)"
      ],
      "metadata": {
        "id": "gdn248Bq928v"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = [itemlist3[0:3200], itemlist3[3201:6400], \n",
        "        itemlist3[6401:9600], itemlist3[9601:12800], itemlist3[12801:16000], itemlist3[16001:19200], itemlist3[19201:22400]]"
      ],
      "metadata": {
        "id": "dpioqKk199lP"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatgptfn(sub_list):\n",
        "    result = ''\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"You are an assistant\"},\n",
        "            {\"role\": \"user\", \"content\": f\"{sub_list} :give me a summary\"}\n",
        "        ]\n",
        "    )\n",
        "    for choice in response.choices:\n",
        "        result += choice.message.content\n",
        "    return result"
      ],
      "metadata": {
        "id": "b_oMT5Jd-LD5"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0,7):\n",
        "    data[i] = chatgptfn(data[i])\n",
        "    time.sleep(20) "
      ],
      "metadata": {
        "id": "XFtl_Aca-QOZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data3 = ''\n",
        "for i in range(0,7):\n",
        "    data3 = data3 + data[i]"
      ],
      "metadata": {
        "id": "V3H4gA-A_Bwa"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "_eFUWZxC_GuR",
        "outputId": "87eaec39-1209-42c7-a12e-4f021ff4a370"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Amazon reported flat online sales in the first quarter of 2022, but offset that with strong performance in its cloud services and advertising units. CEO Andy Jassy said the company is doing well despite uncertainties in the economy. Amazon's cost-cutting measures appear to be paying off, with profits increasing. The company has been shedding employees and winding down some programmes, while halting real estate expansion plans and overhauling its delivery network in the US. Despite concerns about the economy, advertising revenues jumped 23%, and sales in Amazon Web Services grew 16%. Overall sales were up 9% to $127.4bn, and profits jumped to $3.2bn from a $3.8bn loss in the same quarter last year. Amazon's performance was better than expected, and shares initially gained over 7% in after-hours trading.I'm sorry, can you please provide me with more context? A summary of what exactly?Sure, what would you like me to summarize?Of what subject or topic would you like a summary? Please provide more context so I can assist you better.Sure, I can give you a summary! However, I need you to specify what it is that you need a summary of. Can you please provide me with more details or context about the topic?I'm sorry, I need more context. Can you please provide me with further information or details on what you need a summary of?I'm sorry, could you be more specific? What do you need a summary of?\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "papers = [data1, data2, data3 ]"
      ],
      "metadata": {
        "id": "f1YHqTQp_KFB"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "from gensim import corpora\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "q4EtbzOuk8yO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 創建詞袋\n",
        "texts = [[word for word in document.lower().split()] for document in data]\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "corpus = [dictionary.doc2bow(text) for text in texts]"
      ],
      "metadata": {
        "id": "7UmParSu_Vx5"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 訓練 LDA 模型\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus, id2word=dictionary, \n",
        "                                            num_topics=3, random_state=100, update_every=1, \n",
        "                                            chunksize=100, passes=10, alpha='auto', per_word_topics=True)"
      ],
      "metadata": {
        "id": "DDVpXLFH_X4B"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy\n",
        "import pandas\n",
        "!pip install pyLDAvis\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 647
        },
        "id": "grxygpJPlIEA",
        "outputId": "9f58d173-abda-4cd8-891b-1ad8e9dc296d"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.10/dist-packages (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.24.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.10.1)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.0.1)\n",
            "Collecting joblib>=1.2.0 (from pyLDAvis)\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (3.1.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.8.4)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (2.0)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (1.2.2)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (4.3.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from pyLDAvis) (67.7.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2022.7.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->pyLDAvis) (2023.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.1.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->pyLDAvis) (6.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->pyLDAvis) (2.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.16.0)\n",
            "Installing collected packages: joblib\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.0.1\n",
            "    Uninstalling joblib-1.0.1:\n",
            "      Successfully uninstalled joblib-1.0.1\n",
            "Successfully installed joblib-1.2.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "joblib"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"pandas<2.0.0\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "RToYNUUCKrL-",
        "outputId": "4070c5d7-d088-408a-ea05-ca7c919f02c0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pandas<2.0.0\n",
            "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0) (2022.7.1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas<2.0.0) (1.24.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<2.0.0) (1.16.0)\n",
            "Installing collected packages: pandas\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.0.1\n",
            "    Uninstalling pandas-2.0.1:\n",
            "      Successfully uninstalled pandas-2.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pyldavis 3.4.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed pandas-1.5.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pandas"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis.gensim_models\n",
        "import pandas\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P1hXmXPDR-Kv",
        "outputId": "1854293a-d615-49a6-9131-c37f6bbaa3b0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pyLDAvis.enable_notebook()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SjBgmmhyR_Fv",
        "outputId": "c6a4965d-ab35-41a0-c344-37013fd3a343"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QteKmR-bSTRH",
        "outputId": "d5e51537-507d-4f38-877d-81e956c75fd9"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 輸出主題模型分析結果\n",
        "import pyLDAvis.gensim_models\n",
        "import pandas\n",
        "\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, dictionary)\n",
        "pyLDAvis.display(vis)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 917
        },
        "id": "bxM9nmql_eM6",
        "outputId": "3f10aa46-238c-4911-ad10-f878e51458df"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el2371406759458642563781343684\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el2371406759458642563781343684_data = {\"mdsDat\": {\"x\": [-0.13656515776382622, 0.10340795477091597, 0.03315720299291035], \"y\": [-0.006659495004009221, -0.016089012358185308, 0.02274850736219459], \"topics\": [1, 2, 3], \"cluster\": [1, 1, 1], \"Freq\": [52.72133752372966, 29.584521045574775, 17.694141430695566]}, \"tinfo\": {\"Term\": [\"you\", \"what\", \"more\", \"can\", \"need\", \"a\", \"i\", \"me\", \"sure,\", \"please\", \"provide\", \"sorry,\", \"summary\", \"i'm\", \"to\", \"in\", \"or\", \"the\", \"and\", \"of?\", \"details\", \"like\", \"would\", \"context\", \"summarize?\", \"of.\", \"it\", \"however,\", \"give\", \"specify\", \"in\", \"and\", \"sales\", \"the\", \"quarter\", \"services\", \"company\", \"jumped\", \"despite\", \"performance\", \"its\", \"amazon's\", \"profits\", \"amazon\", \"advertising\", \"cost-cutting\", \"ceo\", \"been\", \"loss\", \"employees\", \"economy.\", \"halting\", \"estate\", \"from\", \"appear\", \"after-hours\", \"expansion\", \"while\", \"trading.\", \"9%\", \"to\", \"with\", \"be\", \"a\", \"of\", \"sorry,\", \"i'm\", \"of?\", \"more\", \"please\", \"provide\", \"summary\", \"subject\", \"topic\", \"better.\", \"assist\", \"summary?\", \"so\", \"context.\", \"further\", \"on\", \"information\", \"exactly?\", \"context?\", \"what\", \"do\", \"specific?\", \"could\", \"or\", \"you\", \"can\", \"need\", \"of\", \"a\", \"i\", \"me\", \"with\", \"context\", \"would\", \"like\", \"sure,\", \"summarize?\", \"of.\", \"it\", \"however,\", \"give\", \"specify\", \"topic?\", \"summary!\", \"i\", \"me\", \"details\", \"like\", \"would\", \"context\", \"that\", \"is\", \"about\", \"you\", \"need\", \"can\", \"to\", \"what\", \"or\", \"a\", \"provide\", \"please\", \"summary\", \"more\", \"with\", \"the\"], \"Freq\": [7.0, 4.0, 3.0, 3.0, 3.0, 4.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 5.0, 2.0, 6.0, 5.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 5.388119346500473, 4.649745127541681, 2.447476209551651, 5.3835949449542895, 1.7155875627143216, 1.7144847398374394, 1.714527335073515, 1.7140544921587597, 1.7138415159783815, 1.7139635745960438, 1.7139206214168077, 1.7137522688170803, 1.7136436927251228, 1.7134172340190401, 1.7131911332561178, 0.9810308672173145, 0.9808803521184086, 0.9807878238114713, 0.9808171154934224, 0.9808255868148829, 0.9807522681242149, 0.9806623647337864, 0.9807047809982818, 0.9806905825862566, 0.9805883898139912, 0.9806083749737746, 0.9805149518089364, 0.9805815292367521, 0.9805202016419542, 0.9805040345425473, 2.44717219649417, 1.7173186951519157, 1.0292593530925283, 1.0043311175798042, 0.9843228704625872, 2.0230900297502425, 2.021254040800235, 1.4096031130522777, 2.637374893946792, 2.039763771423135, 2.0393666054085684, 2.0212916684637863, 0.8171390130117295, 0.8171060051146997, 0.817079692531469, 0.8170052406420222, 0.8168418080321845, 0.8166477778382847, 0.8161529271953883, 0.8158973670676741, 0.8157442452410872, 0.8156725384302981, 0.8153861798591078, 0.8150500081532517, 2.6373250808121265, 0.7789717071682012, 0.7789559062276351, 0.7789117841096986, 1.4291141948069808, 4.462467622464908, 2.0398249665912593, 2.023930425538314, 1.4287642977078363, 2.6357307926902687, 1.4292522521775195, 1.4265773404084765, 1.429721058049737, 0.8173400732851185, 0.8172608007697364, 0.8171289030878928, 1.1240091666456382, 0.6425270509423726, 0.6423121756124777, 0.6422531509691186, 0.6422050182545204, 0.6421440314622301, 0.6421228883064, 0.6420407583582795, 0.6419988724851765, 1.1262268754641698, 1.1261620044178728, 0.6446051268359427, 0.6431955030262221, 0.6431044032544161, 0.6430589935220081, 0.6440747059228253, 0.6437983632743711, 0.6437755382766, 2.572476877924158, 1.1283073139452284, 1.1265459449066972, 1.1301266664868697, 1.1265702915709865, 0.6443935351022184, 1.1290716710635726, 0.6446011624942246, 0.6444100732146386, 0.6448124739209588, 0.64499110956141, 0.6469743215607346, 0.6554222536744028], \"Total\": [7.0, 4.0, 3.0, 3.0, 3.0, 4.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 5.0, 2.0, 6.0, 5.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 5.7703139205102625, 5.031976355393462, 2.8213773544685954, 6.250666663154432, 2.085248679829393, 2.084772830833258, 2.0849092782174923, 2.0848040091730526, 2.084635396185404, 2.08479462333209, 2.0847436627368516, 2.084539793391723, 2.0845637566869963, 2.0845209379911878, 2.0846024171048363, 1.3482399159248817, 1.3482496935629094, 1.348126794226388, 1.3481963242375927, 1.348208564044437, 1.348159776445994, 1.3480919901592143, 1.34816396892813, 1.3482125819624273, 1.348113979471284, 1.3481562251880388, 1.3480357081471332, 1.348129342440807, 1.3480855768552307, 1.3481054845296578, 3.785294744981427, 3.794014074762387, 1.9697646507445215, 4.769133581333645, 2.575609090995568, 2.455153725177076, 2.455157941593179, 1.8415320025409954, 3.550009321500367, 2.933615066870995, 2.9335938826926076, 2.937148755600461, 1.224454288835724, 1.224439557478019, 1.2244369945818256, 1.2244221167139906, 1.2243899658450106, 1.2243446164407423, 1.2242308486596538, 1.2241750319823976, 1.2241444937985717, 1.2241301988454794, 1.225120846211797, 1.2251819952912013, 4.032174218456389, 1.2325029722642875, 1.232506525792777, 1.2325187954563317, 2.319566195391714, 7.321571184744721, 3.415461349434085, 3.417750192013849, 2.575609090995568, 4.769133581333645, 2.801557861655656, 2.802134795077948, 3.794014074762387, 1.7064449297075392, 1.7064366151176316, 1.7064148925951783, 1.5752040516350445, 1.0931152041290018, 1.0931687052877115, 1.0931853753671674, 1.0931983515499981, 1.093216707163897, 1.0932209827751058, 1.0932426965916673, 1.0932558095423168, 2.801557861655656, 2.802134795077948, 1.706021468302327, 1.7064148925951783, 1.7064366151176316, 1.7064449297075392, 1.829967793367679, 1.830042384284378, 1.830089916823436, 7.321571184744721, 3.417750192013849, 3.415461349434085, 3.785294744981427, 4.032174218456389, 2.319566195391714, 4.769133581333645, 2.9335938826926076, 2.933615066870995, 2.937148755600461, 3.550009321500367, 3.794014074762387, 6.250666663154432], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -3.1687, -3.3161, -3.9579, -3.1696, -4.3132, -4.3138, -4.3138, -4.314, -4.3142, -4.3141, -4.3141, -4.3142, -4.3143, -4.3144, -4.3146, -4.8721, -4.8722, -4.8723, -4.8723, -4.8723, -4.8723, -4.8724, -4.8724, -4.8724, -4.8725, -4.8725, -4.8726, -4.8725, -4.8726, -4.8726, -3.958, -4.3121, -4.8241, -4.8486, -4.8687, -3.5705, -3.5714, -3.9318, -3.3054, -3.5623, -3.5625, -3.5714, -4.4771, -4.4771, -4.4772, -4.4773, -4.4775, -4.4777, -4.4783, -4.4786, -4.4788, -4.4789, -4.4792, -4.4796, -3.3054, -4.5249, -4.5249, -4.525, -3.9181, -2.7794, -3.5623, -3.5701, -3.9183, -3.306, -3.918, -3.9199, -3.9177, -4.4768, -4.4769, -4.4771, -3.6442, -4.2035, -4.2038, -4.2039, -4.204, -4.2041, -4.2041, -4.2042, -4.2043, -3.6423, -3.6423, -4.2002, -4.2024, -4.2026, -4.2026, -4.2011, -4.2015, -4.2015, -2.8163, -3.6404, -3.642, -3.6388, -3.6419, -4.2006, -3.6397, -4.2002, -4.2005, -4.1999, -4.1996, -4.1966, -4.1836], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.5716, 0.5611, 0.498, 0.4908, 0.445, 0.4446, 0.4446, 0.4443, 0.4443, 0.4443, 0.4443, 0.4443, 0.4442, 0.4441, 0.4439, 0.3222, 0.322, 0.322, 0.322, 0.322, 0.322, 0.3219, 0.3219, 0.3219, 0.3218, 0.3218, 0.3218, 0.3218, 0.3218, 0.3218, 0.204, -0.1525, -0.0089, -0.9177, -0.3217, 1.0244, 1.0234, 0.9506, 0.9208, 0.8545, 0.8543, 0.8442, 0.8135, 0.8134, 0.8134, 0.8133, 0.8132, 0.813, 0.8125, 0.8122, 0.812, 0.8119, 0.8108, 0.8103, 0.7934, 0.7591, 0.7591, 0.759, 0.7336, 0.7228, 0.7025, 0.694, 0.6286, 0.6249, 0.5449, 0.5428, 0.242, 0.4818, 0.4817, 0.4816, 1.3945, 1.2006, 1.2002, 1.2001, 1.2, 1.1999, 1.1998, 1.1997, 1.1996, 0.8206, 0.8204, 0.7587, 0.7562, 0.7561, 0.756, 0.6877, 0.6872, 0.6872, 0.686, 0.6237, 0.6228, 0.5231, 0.4568, 0.4511, 0.2912, 0.2166, 0.2163, 0.2157, 0.0265, -0.0369, -0.5232]}, \"token.table\": {\"Topic\": [1, 1, 2, 3, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 3, 1, 1, 2, 3, 2, 2, 1, 2, 1, 2, 3, 2, 1, 1, 1, 2, 1, 1, 2, 3, 1, 3, 2, 3, 2, 1, 2, 1, 3, 3, 1, 1, 2, 3, 1, 2, 3, 2, 3, 2, 3, 1, 2, 3, 2, 2, 2, 3, 1, 2, 3, 1, 2, 3, 1, 1, 1, 2, 2, 2, 3, 2, 3, 2, 3, 3, 2, 3, 1, 3, 1, 3, 1, 3, 2, 3, 1, 2, 3, 1, 1, 2, 3, 2, 3, 2, 3], \"Freq\": [0.7417817162496682, 0.2096816922708965, 0.6290450768126895, 0.2096816922708965, 0.5464212390917612, 0.5464212390917612, 0.9594155622143359, 0.7417537977547977, 0.9594530635549101, 0.9594443849622225, 0.9936453685122767, 0.7417770420214687, 0.8167118074310211, 0.5076748634015872, 0.5076748634015872, 0.741769990985041, 0.8167018837433312, 0.5855724294263743, 0.29278621471318717, 0.741702375141938, 0.9592743535152349, 0.5860136372355046, 0.5860136372355046, 0.8168394066322112, 0.8162052689668525, 0.7417077540787747, 0.8113466534437366, 0.9594003841917511, 0.5861590950523656, 0.5861590950523656, 0.8113570697219937, 0.7417518438624466, 0.7417250021021524, 0.7417495371835661, 0.8162460079690143, 0.741820112001702, 0.7417227916271356, 0.8168766507029845, 0.9147317210274561, 0.7417891414679324, 0.9147470800538107, 0.35694426079389385, 0.35694426079389385, 0.8146115433625334, 0.8665039838175486, 0.8169065683888327, 0.5464354315438662, 0.5464354315438662, 0.9147579381622543, 0.9593505598546346, 0.9593227906316765, 0.586023952521396, 0.586023952521396, 0.7417317359662003, 0.35687076929937006, 0.35687076929937006, 0.8450682035764592, 0.2816894011921531, 0.5851802758063881, 0.29259013790319405, 0.3882576760177, 0.3882576760177, 0.9147718875988219, 0.5430261318403227, 0.8168970289585326, 0.43111509470464854, 0.43111509470464854, 0.9593271095468558, 0.6817527025224913, 0.34087635126124566, 0.9594333555806449, 0.6817576256207264, 0.3408788128103632, 0.9591182190143538, 0.7088736275678723, 0.959337137562669, 0.8167635047941582, 0.8146129423548628, 0.8113547304398868, 0.9147281434916595, 0.81669034860489, 0.9148166599665986, 0.6809324846712187, 0.34046624233560935, 0.9146990039034344, 0.8167332532081408, 0.6348383874216239, 0.5464577046788927, 0.5464577046788927, 0.7999146762173883, 0.15998293524347765, 0.5283604407956911, 0.26418022039784556, 0.8167001742901073, 0.9147099753034125, 0.7417926704124873, 0.7440154709258744, 0.24800515697529146, 0.7417685889022236, 0.527146173047673, 0.2635730865238365, 0.2635730865238365, 0.5860164925792254, 0.5860164925792254, 0.5463308214955868, 0.40974811612169004], \"Term\": [\"9%\", \"a\", \"a\", \"a\", \"about\", \"about\", \"advertising\", \"after-hours\", \"amazon\", \"amazon's\", \"and\", \"appear\", \"assist\", \"be\", \"be\", \"been\", \"better.\", \"can\", \"can\", \"ceo\", \"company\", \"context\", \"context\", \"context.\", \"context?\", \"cost-cutting\", \"could\", \"despite\", \"details\", \"details\", \"do\", \"economy.\", \"employees\", \"estate\", \"exactly?\", \"expansion\", \"from\", \"further\", \"give\", \"halting\", \"however,\", \"i\", \"i\", \"i'm\", \"in\", \"information\", \"is\", \"is\", \"it\", \"its\", \"jumped\", \"like\", \"like\", \"loss\", \"me\", \"me\", \"more\", \"more\", \"need\", \"need\", \"of\", \"of\", \"of.\", \"of?\", \"on\", \"or\", \"or\", \"performance\", \"please\", \"please\", \"profits\", \"provide\", \"provide\", \"quarter\", \"sales\", \"services\", \"so\", \"sorry,\", \"specific?\", \"specify\", \"subject\", \"summarize?\", \"summary\", \"summary\", \"summary!\", \"summary?\", \"sure,\", \"that\", \"that\", \"the\", \"the\", \"to\", \"to\", \"topic\", \"topic?\", \"trading.\", \"what\", \"what\", \"while\", \"with\", \"with\", \"with\", \"would\", \"would\", \"you\", \"you\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [2, 3, 1]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el2371406759458642563781343684\", ldavis_el2371406759458642563781343684_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el2371406759458642563781343684\", ldavis_el2371406759458642563781343684_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el2371406759458642563781343684\", ldavis_el2371406759458642563781343684_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    }
  ]
}